{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言理解\n",
    "\n",
    "## 实验目的：\n",
    "- 了解自然语言理解\n",
    "- 了解意图识别\n",
    "- 掌握创建和使用微软语言理解模型\n",
    "- 掌握创建和使用微软认知服务\n",
    "- 掌握连接和使用云端接口服务\n",
    "\n",
    "## 实验内容：\n",
    "- 基础知识介绍\n",
    "- 创建语言理解模型使用并测试\n",
    "- 添加语音控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='RoyalBlue'>1. 自然语言理解介绍 </font>\n",
    "\n",
    "我们越来越渴望计算机能够使用AI来理解自然语言中的口头或键入命令。例如，您可能希望实现家庭自动化系统，该系统使您能够使用语音命令（如\"打开灯\"或\"打开风扇\"）控制家中的设备，并且让AI设备了解该命令并采取适当措施。\n",
    "\n",
    "![A robot listening](./images/language_understanding.jpg)\n",
    "\n",
    "\n",
    "自然语言处理(NLP)是使用自然语言同计算机进行通讯的技术, 因为处理自然语言的关键是要让计算机“理解”自然语言,所以自然语言处理又叫做自然语言理解(NLU) 也称为计算语言学，它是人工智能的核心课题之一 。\n",
    "\n",
    "自然语言理解俗称人机对话，研究用电子计算机模拟人的语言交际过程，使计算机能理解和运用人类社会的自然语言如汉语，英语等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='RoyalBlue'>1.1 意图识别 </font>\n",
    "\n",
    "### 1.1.1 概述\n",
    "意图识别是通过分类的办法将句子或者我们常说的`查询指令(query)`分到相应的`意图（intent）`种类。\n",
    "> 例子：<br>\"我想听周杰伦的歌\"，这个query的意图便是属于`音乐`意图，我想听郭德纲的相声便是属于`电台`意图。做好了意图识别以后对于很多nlp的应用都有很重要的提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 聊天机器人和意图识别<br>目前各式各样的聊天机器人，智能客服所能处理的问题种类都是有限制的。比如某聊天机器人目前只有30个技能，那么用户向聊天机器人发出一个指令，聊天机器人首先得根据意图识别将用户的query分到某一个或者某几个技能上去，然后再进行后续的处理。做好了意图识别以后，人机交互就有了实现的可能，用户向机器发来的每一个query，机器都能准确的理解用户的意图，然后准确的给予回复。\n",
    "<img width = \"700\" height = \"300\" src=./data/luis/notebook/nlu.png> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width = \"700\" height = \"300\" src=./data/luis/notebook/nlu2.png> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 意图识别的方法之一\n",
    "不同的意图会有的不同的领域词典，比如书名，歌曲名，商品名等等。当一个用户的意图来了以后我们根据意图和词典的匹配程度或者重合程度来进行判断，最简单一个规则是哪个领域（domain）的词典重合程度高，就将该query判别给这个领域。\n",
    "\n",
    "\n",
    "\n",
    "### 1.1.3 意图识别的难点\n",
    "意图识别工作最大的难点其实是在于标注数据的获取。目前标注数据的获取主要来自两方面，一方面是专门的数据标注团队对数据进行标注，一方面是通过半监督的方式自动生成标注数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='RoyalBlue'>2. 创建语言理解模型 </font>\n",
    "\n",
    "## 2.1 创建认证和预测资源\n",
    "\n",
    "Microsoft 认知服务包括语言理解服务，它使您能够定义基于声明应用于 **实体（entity）** 的 **意图（intent）**。您可以使用 **语言理解（language understanding）**或**认知服务(cognitive service)**资源来使用语言理解应用，但您必须创建单独的**语言理解**资源来*制作（authoring）*应用。\n",
    "\n",
    "1. 在另一个浏览器选项卡中，打开 Azure 门户，网址为 [https://portal.azure.cn](https://portal.azure.cn) ，使用 Azure 帐户登录。\n",
    "2. 单击 **+ 创建资源**，并搜索 **语言理解**。<br>\n",
    "<img style=\"float: left;\" width = \"850\" height = \"300\" src=./data/luis/notebook/01.png> <br>\n",
    "<img width = \"700\" height = \"300\" src=./data/luis/notebook/02.png> <br>\n",
    "3. 在服务列表中，单击 **语言理解**。<br>\n",
    "<img style=\"float: left;\" width = \"850\" height = \"50\" src=./data/luis/notebook/03.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 在 **语言理解**边栏选项卡中，单击**创建**。\n",
    "5. 在 **创建**边栏选项卡中，输入以下详细信息，然后单击 **创建**\n",
    "  - **创建选项**： 两者\n",
    "  - **名称**： *您的服务的唯一名称*\n",
    "  - **订阅**： *选择 Azure 订阅*\n",
    "  - **资源组**： *选择现有资源组或创建新资源组*\n",
    "  - **创作位置**：*选择任何可用位置*\n",
    "  - **创作定价层**： F0\n",
    "  - **预测位置**： *与创作位置相同*\n",
    "  - **预测定价层**： F0\n",
    "<img style=\"float: left;\" width = \"850\" height = \"50\" src=./data/luis/notebook/04.png> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "6. 等待创建资源，并注意已预配两个语言理解资源;一个用于创作，另一个用于预测。您可以通过导航到创建它们的资源组来查看它们。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/05.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 创建语言理解应用\n",
    "\n",
    "若要使用语言理解实现自然语言理解，请创建一个应用;然后添加实体、意图和话语来定义您希望应用理解的命令：\n",
    "\n",
    "1. 在新的浏览器选项卡中，打开[https://luis.azure.cn](https://luis.azure.cn)\n",
    "，的语言理解门户，并使用与 Azure 订阅关联的帐户登录。如果这是您第一次登录\"语言理解\"门户，您可能需要授予应用一些访问帐户详细信息的权限。然后通过选择刚刚在 Azure 订阅中创建的现有语言理解创作资源来完成 *欢迎* 步骤。\n",
    "2. 打开 **我的LUIS**页面，并选择您的订阅和语言理解创作资源。然后创建一个新应用，用于使用以下设置进行对话：\n",
    "  - **名称**：Family Automation\n",
    "  - **区域性**：Chinese\n",
    "  - **说明**：简单的家庭自动化\n",
    "  - **预测资源**：*您的语言理解预测资源*\n",
    "  \n",
    "<img style=\"float: left;\" width = \"650\" height = \"50\" src=./data/luis/notebook/07.png> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 如果显示语言理解应用提示的面板，请关闭它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 创建实体\n",
    "\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/08.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`实体（entity）` 是您的语言模型可以识别和执行某项操作的一个物体。在这种情况下，您的语言理解应用将用于控制家里的各种 `设备`，如灯或风扇;因此，您将创建一个 `设备（device）` 实体，该实体包含您希望应用使用的设备类型的列表。对于每种设备类型，您将创建一个子列表，用于标识设备的名称（例如：灯）以及可用于引用此类设备的任何同义词（例如：电灯）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在应用的语言理解页面中，在左侧的窗格中，单击 **实体**。然后单击 **创建**，并创建一个名为 **设备** 的新实体，选择 **列表（list）** 类型，然后单击 **创建** 。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/09.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 在 **列表项**页面中，在**规范化值**下，输入 **灯**，然后按 Enter。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/10.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 添加 <b>灯</b> 值后，在 **同义词** 下，输入 **电灯** 和 **光**， 并按 Enter。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/11.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 添加第二个列表项名为 **风扇** 与同义词 **电风扇** 和 **风**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 创建意图\n",
    "\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/12.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`意图（intent）` 是您希望对一个或多个`实体（entity）`执行的操作 - 例如，您可能希望打开灯或关闭风扇。在这种情况下，您将定义两个目的：一个用于打开设备，另一个用于关闭设备。对于每个意图，您将指定示例用于确定意图的种类。\n",
    "\n",
    "1. 在左侧的窗格中，单击**意图**。然后单击 **创建**，并添加名称 <b>开</b>，并点击完成。\n",
    "2. 在 **示例** 标题和 **示例用户输入** 副标题下，输入 **开灯** 并按 **Enter** 将此话语提交到列表中。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/13.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 在 *开灯* 话语中，单击词语\"灯\"，并将其分配给 **设备** 实体的 **灯** 值。\n",
    "<img style=\"float: left;\" width = \"750\" height = \"500\" src=./data/luis/notebook/14.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 在 <b>开</b>意图中添加第二个话语，短语 **开风扇**。然后将词语 **风扇** 分配给 **设备** 实体的 **风扇** 。\n",
    "5. 在左侧的窗格中，单击 **意图** 并单击 **创建**，以添加第二个意图 **关**。\n",
    "6. 在 <b>关</b> 意图的页面中，添加话语 **关灯** 并将\"灯\"一词分配给 **设备** 的 **灯**值。\n",
    "7. 在 <b>关</b> 意图中添加第二个话语，短语 <b>关风扇</b>。然后将单词风扇连接到 <b>设备</b> 实体的 **风扇** 值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 训练和测试语言模型\n",
    "<img src=./data/luis/notebook/15.png>\n",
    "现在，您可以使用以实体、意图形式提供的数据来训练应用的语言模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在应用的语言理解页面顶部，单击 **训练** 以训练语言模型\n",
    "2. 训练模型时，单击 **测试**，并使用\"测试\"窗格查看以下短语的预测意图：\n",
    "    * 开灯\n",
    "    * 关风扇\n",
    "    * 关灯 \n",
    "    * 开电风扇\n",
    "3. 关闭测试窗格。    \n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/16.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 发布模型并配置终结点\n",
    "\n",
    "\n",
    "若要在客户端应用程序中使用已训练的模型，必须将其发布为客户端应用程序，这样可以向其发送新话语的终结点，这样意图和要求才能被预测。\n",
    "\n",
    "1. 在应用的语言理解页面顶部，单击 **发布**。然后选择 **生产槽**然后单击**完成**。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/17.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'red'>创建好后会生成应用ID，主密钥和终结点 URL等关键信息，用于2.3云端接口调用</font>\n",
    "\n",
    "2. 模型发布后，在应用的语言理解页面顶部，单击 **管理**。然后在 **应用程序设置** 选项卡上，记下应用的 **应用ID**。复制此内容并将其粘贴到下面的代码中，以替换 `YOUR_LU_APP_ID` 。\n",
    "3. 在 **Azure 资源** 选项卡上，记下预测资源的 **主密钥** 和 **终结点 URL**。复制这些内容并将其粘贴到下面的代码中，替换 `YOUR_LU_KEY`和`YOUR_LU_ENDPOINT` 。\n",
    "\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/18.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 通过单击其 <b>运行单元格</b>（&#9655;）运行下面的单元格，并在提示时输入文本 <b>开灯</b>。文本由语言理解模型解释，并显示相应的图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 连接云端接口使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_code import luis    # 获取语言理解luis库\n",
    "import matplotlib.pyplot as plt # 获取matplot\n",
    "from PIL import Image # 获取python_image库\n",
    "import os # 获取标准库\n",
    "%matplotlib inline\n",
    "import requests # 获取网址信息HTTP库\n",
    "\n",
    "try:\n",
    "    # 配置api\n",
    "    luis_app_id = 'b6802735-b1d4-44c9-b820-aa7b0e932316'           # 应用id\n",
    "    luis_key = 'd9bf5f21b9364ad09d7822ab952677e6'          # 密钥\n",
    "    luis_endpoint = 'https://languageunderstand.cognitiveservices.azure.cn/' # 终结点\n",
    "    #luis_app_id = 'YOUR_LU_APP_ID '    # 应用id\n",
    "    #luis_key = 'YOUR_LU_KEY'         # 密钥\n",
    "    luis_endpoint = 'YOUR_LU_ENDPOINT' # 终结点\n",
    "    \n",
    "    # 请求指令\n",
    "    command = input('请输入指令:\\n')\n",
    "    \n",
    "    headers = {\n",
    "    }\n",
    "   \n",
    "    # 获取实体和意图\n",
    "    params ={\n",
    "        'query': command,\n",
    "        'timezoneOffset': '0',\n",
    "        'verbose': 'true',\n",
    "        'show-all-intents': 'true',\n",
    "        'spellCheck': 'false',\n",
    "        'staging': 'false',\n",
    "        'subscription-key': luis_key\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    response = requests.get(f'{luis_endpoint}luis/prediction/v3.0/apps/{luis_app_id}/slots/production/predict', headers=headers, params=params)\n",
    "    \n",
    "    \n",
    "    prediction_result = response.json()\n",
    "    print(prediction_result) # 展示预测结果\n",
    "    \n",
    "    \n",
    "    intent = str(prediction_result['prediction']['topIntent'])\n",
    "    entity_keys = list(prediction_result['prediction']['entities'].keys())\n",
    "    entity = str(prediction_result['prediction']['entities'][entity_keys[0]][0][0])\n",
    "    action = str(intent + entity)\n",
    "    img_name = action + '.jpg'\n",
    "    \n",
    "    # 展示图片\n",
    "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
    "    plt.axis('off')\n",
    "    plt. imshow(img)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    img = Image.open(os.path.join(\"data\", \"luis\" ,'unknown.jpg'))\n",
    "    plt.axis('off')\n",
    "    plt. imshow(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新运行上面的单元格，尝试以下短语：\n",
    "\n",
    "* `打开灯`\n",
    "* `把灯关上`\n",
    "* `打开风扇`\n",
    "* `打开灯`\n",
    "* `关灯`\n",
    "* `关闭风扇`\n",
    "* `打开电风扇`\n",
    "* `把灯开开`\n",
    "\n",
    ">**注意**：如果您对用于从语言理解应用中检索意图和权限的代码感到好奇，请查看<b>python_code</b>文件夹中的文件，<b>luis.py</b> 。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.4 自由练习 \n",
    "\n",
    "### 现在我们可以继续往模型中添加更多的实体和意向。\n",
    "\n",
    "- 1. 在现有设备下，添加实体。例如：电脑、洗衣机、吸尘器、热水器等。\n",
    "- 2. 添加意向，例如：待机、重启、延长持续时间等，并分配意向对应的实体语句。\n",
    "- 3. 添加完成后重新进行训练和发布。\n",
    "- 4. 在云端上传保存对应的意向实体图片，例如：打开电脑。 注意：请将图片上传到该文件同文件夹下的 data/luis／文件夹中\n",
    "- 5. 让模型展示出新上传的对应图片\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='royalblue'>3. 添加语音控制 </font>\n",
    "\n",
    "越来越多的人工智能系统使人类能够通过语音识别与软件服务进行通信。为了支持这一点，**语音** 认知服务提供了一种将口语转录成文本的简单方法。\n",
    "\n",
    "## 3.1  创建认知服务资源 </font>\n",
    "\n",
    "如果还没有，请使用以下步骤在 Azure 订阅中创建 **认知服务** 资源：\n",
    "\n",
    "1. 在另一个浏览器选项卡中，打开 Azure 门户，网址为 [https://portal.azure.cn](https://portal.azure.cn) ，使用 Azure 帐户登录。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/01.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 单击 **&#65291;创建资源**按钮，搜索 *认知服务*，选择蓝色图标的并创建具有以下设置的 **认知服务**资源：\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/19.png>\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/20.png>\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/21.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 名称： *输入唯一名称*。\n",
    "- 订阅： *您的 Azure 订阅*。\n",
    "- 位置： *任何可用位置*。\n",
    "- 定价层： S0\n",
    "- 资源组： *创建具有唯一名称的资源组*。\n",
    "    \n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/22.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 等待部署完成。点击 **转到资源**，然后转到您的认知服务资源。\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/23.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 获取认知服务资源的关键和端点\n",
    "\n",
    "要使用认知服务资源，客户端应用程序需要其终结点和身份验证密钥：\n",
    "\n",
    "- 1. 在 Azure 门户中，在认知服务资源的 **密钥和终结点**  页面上，复制资源中的 **密钥1** 并将其粘贴到下面的代码中，替换 **YOUR_COG_KEY** 。\n",
    "- 2. 复制资源中的 **终结点**并将其粘贴到下面的代码中，替换 **YOUR_COG_ENDPOINT** 。\n",
    "- 3. 复制 \"位置\"， 然后将其粘贴到下面的代码中， 替换 **YOUR_COG_REGION** 。\n",
    "- 4. 在下面的单元格中运行代码。\n",
    "\n",
    "<img style=\"float: left;\" width = \"850\" height = \"500\" src=./data/luis/notebook/24.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 连接接口使用语言控制\n",
    "### <font color = 'red'>3.3.1 动手配置秘钥</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599696409914
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置api\n",
    "cog_key = '83a99063ece549fb94cb1e6c3aae7d23'            # 密钥1\n",
    "cog_endpoint = 'https://02d.cognitiveservices.azure.cn/' # 终结点\n",
    "cog_region = 'chinaeast2'   \n",
    "\n",
    "print('位置为：{} \\n密钥为：{}'.format(cog_region, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### 若要在认知服务资源中使用语音服务，需要安装 Azure 认知服务语音 SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install azure.cognitiveservices.speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 传入音频文件并识别\n",
    "\n",
    "><font color='red'>**注意**</font>：默认音频流格式为 WAV（16kHz 或 8kHz，16 位，单声道 PCM）。 除了 WAV/PCM 外，还支持下列压缩输入格式。 若要启用下列格式，需要其他配置。\n",
    "- MP3\n",
    "- OPUS/OGG\n",
    "- FLAC\n",
    "- wav 容器中的 ALAW\n",
    "- wav 容器中的 MULAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599696420498
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from python_code import luis\n",
    "import os\n",
    "import IPython \n",
    "import matplotlib.pyplot as plt\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:   \n",
    "\n",
    "    # 获取语音信息文件\n",
    "    file_name = '关灯.wav'    # 输入的音频文件名称，从这修改不同的名称\n",
    "    audio_file = os.path.join('data', 'luis', file_name) # 文件位置在 data/luis/ 中\n",
    "\n",
    "    # 配置语音\n",
    "    speech_config = SpeechConfig(cog_key, cog_region)\n",
    "    \n",
    "    # 设置语音识别器环境为中文\n",
    "    speech_config.speech_recognition_language= 'zh-CN'\n",
    "    \n",
    "    # 配置音频\n",
    "    audio_config = AudioConfig(filename=audio_file) \n",
    "    \n",
    "    # 配置语音识别器\n",
    "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # 识别器运作一次\n",
    "    speech = speech_recognizer.recognize_once()\n",
    "    \n",
    "    # 展示识别出的文本\n",
    "    print(speech.text)\n",
    "    \n",
    "    # 将文本输入我们刚刚建立的luis语言理解模型当中\n",
    "    headers = {\n",
    "    }\n",
    "    \n",
    "    params ={\n",
    "        'query': speech.text,\n",
    "        'timezoneOffset': '0',\n",
    "        'verbose': 'true',\n",
    "        'show-all-intents': 'false',\n",
    "        'spellCheck': 'false',\n",
    "        'staging': 'false',\n",
    "        'subscription-key': luis_key\n",
    "    }\n",
    "    response = requests.get(f'{luis_endpoint}luis/prediction/v3.0/apps/{luis_app_id}/slots/production/predict', headers=headers, params=params)\n",
    "    \n",
    "    # 展示图片\n",
    "    prediction_result = response.json()\n",
    "    \n",
    "    intent = str(prediction_result['prediction']['topIntent'])\n",
    "    entity_keys = list(prediction_result['prediction']['entities'].keys())\n",
    "    entity = str(prediction_result['prediction']['entities'][entity_keys[0]][0][0])\n",
    "    action = str(intent + entity)\n",
    "    \n",
    "    img_name = action + '.jpg'\n",
    "\n",
    "    # 播放对应音频并展示图片\n",
    "    IPython.display.display(IPython.display.Audio(audio_file, autoplay=True),\n",
    "                            IPython.display.Image(data=os.path.join(\"data\", \"luis\" ,img_name)))\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    print('未知指令')\n",
    "    img = Image.open(os.path.join(\"data\", \"luis\" ,'unknown.jpg'))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 尝试传入不同的音频文件\n",
    "实验环境默认提供了下方三个wav格式的音频文件，可以尝试修改代码``` file_name = '关灯.wav'```看看使用效果,也可自己制作音频文件进行测试。\n",
    "- `关灯.wav`\n",
    "- `开风扇.wav`\n",
    "- `关风扇.wav`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">3.4 自由练习  </font>\n",
    "    \n",
    "### 3.4.1 自定义语音识别   \n",
    "\n",
    "\n",
    "> <font color=\"red\">注意:</font><br>\n",
    "使用该网址进行音频文件格式的在线转换（转化为`wav`格式）：https://online-audio-converter.com/cn/ <br>\n",
    "上传自定义语音文件，到该文件的同文件下的 `data/luis` 下，让语音识别器识别你的语音并转化为文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置api\n",
    "cog_key = 'YOUR_COG_KEY'            # 密钥1\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT' # 终结点\n",
    "cog_region = 'YOUR_COG_REGION'      # 位置\n",
    "try:   \n",
    "\n",
    "    # 获取语音信息文件\n",
    "    file_name = '关灯.wav'    # 输入的音频文件名称，从这修改不同的名称\n",
    "    audio_file = os.path.join('data', 'luis', file_name) # 文件位置在 data/luis/ 中\n",
    "\n",
    "    speech_config = SpeechConfig(cog_key, cog_region)\n",
    "\n",
    "    # 设置语音识别器环境为中文\n",
    "    speech_config.speech_recognition_language= 'zh-CN'\n",
    "\n",
    "    # 配置音频\n",
    "    audio_config = AudioConfig(filename=audio_file) \n",
    "\n",
    "    # 配置语音识别器\n",
    "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # 识别器运作一次\n",
    "    speech = speech_recognizer.recognize_once()\n",
    "\n",
    "    # 展示识别出的文本\n",
    "    print(speech.text)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 识别不同语言\n",
    "\n",
    "该文档中有语音识别器支持识别的所有语言：https://docs.azure.cn/zh-cn/cognitive-services/speech-service/language-support#speech-to-text <br>\n",
    "\n",
    "尝试修改语音识别器的环境，并使用或者上传不同语言的语音进行识别。<br><br>\n",
    "><font color=\"red\">注意:</font><br>\n",
    "上传自定义语音文件，到该文件的同文件下的 `data/luis` 下，让语音识别器识别你的语音并转化为文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置api\n",
    "cog_key = '83a99063ece549fb94cb1e6c3aae7d23'            # 密钥1\n",
    "cog_endpoint = 'https://02d.cognitiveservices.azure.cn/' # 终结点\n",
    "cog_region = 'chinaeast2'   \n",
    "try:   \n",
    "\n",
    "    # 获取语音信息文件\n",
    "    file_name = '日文.wav'    # 输入的音频文件名称，从这修改不同的名称\n",
    "    audio_file = os.path.join('data', 'luis', file_name) # 文件位置在 data/luis/ 中\n",
    "\n",
    "    speech_config = SpeechConfig(cog_key, cog_region)\n",
    "\n",
    "    # 设置语音识别器环境为中文\n",
    "    speech_config.speech_recognition_language= 'ja-Jp'   # 在这行修改语音识别器的环境\n",
    "\n",
    "    # 配置音频\n",
    "    audio_config = AudioConfig(filename=audio_file) \n",
    "\n",
    "    # 配置语音识别器\n",
    "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # 识别器运作一次\n",
    "    speech = speech_recognizer.recognize_once()\n",
    "\n",
    "    # 展示识别出的文本\n",
    "    print(speech.text)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 了解更多\n",
    "\n",
    "想了解更多有关于语言理解的知识：[服务文档](https://docs.azure.cn/zh-cn/cognitive-services/luis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
